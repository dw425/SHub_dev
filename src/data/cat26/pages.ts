import { registerPages } from '../pageRegistry'
import type { PageData } from '../pageTypes'

const pages: PageData[] = [
  {
    slug: 'data-quality',
    badge: '‚ú® Page 26.1',
    title: 'Data Quality Management',
    description: 'Implement comprehensive data quality frameworks with profiling, cleansing, validation rules, and continuous monitoring to ensure your organization can trust its data for critical decisions.',
    accentColor: '#EF4444',
    accentLight: '#F87171',
    metrics: [
      { value: '6', label: 'Quality Dimensions' },
      { value: '99.5%', label: 'Target Threshold' },
      { value: 'Real-time', label: 'Monitoring' },
      { value: 'ML', label: 'Anomaly Detection' },
    ],
    overview: {
      title: 'Data Quality Management',
      subtitle: '',
      subsections: [
        {
          heading: 'Data Quality Dimensions',
          paragraphs: [
            'The six pillars of data quality measurement',
            'Data quality is multidimensional‚Äîa dataset can be accurate but not timely, complete but not consistent. The six canonical dimensions provide a framework for comprehensive quality assessment. Accuracy measures whether data correctly represents real-world entities. Completeness evaluates the presence of required values. Consistency ensures data doesn\'t contradict itself across systems. Timeliness verifies data is current enough for its intended use. Validity confirms data conforms to defined formats and business rules. Uniqueness identifies and prevents duplicate records that skew analytics.',
          ],
        },
        {
          heading: 'Data Quality Pipeline',
          paragraphs: [
            'End-to-end quality assurance workflow',
            'A robust data quality pipeline integrates checks at every stage of the data lifecycle. Source profiling establishes baseline expectations before ingestion. Validation rules gate incoming data, quarantining records that fail critical checks. Cleansing transforms and standardizes data to meet quality standards. Enrichment fills gaps using reference data and inference. Monitoring tracks quality metrics over time, alerting on degradation. Remediation workflows route issues to appropriate stewards for resolution.',
          ],
        },
      ],
    },
    concepts: {
      title: 'Data Quality Dimensions',
      subtitle: 'Core components and patterns',
      columns: 2,
      cards: [
        {
          className: 'dimension-0',
          borderColor: '#3B82F6',
          icon: 'üéØ',
          title: 'Accuracy',
          description: 'Data correctly represents the real-world entity or event it describes. Verified through source comparison, business rule validation, and expert review.',
          examples: [],
        },
        {
          className: 'dimension-1',
          borderColor: '#10B981',
          icon: 'üìä',
          title: 'Completeness',
          description: 'All required data elements are present and populated. Distinguishes between mandatory fields, optional fields, and conditional requirements.',
          examples: [],
        },
        {
          className: 'dimension-2',
          borderColor: '#8B5CF6',
          icon: 'üîó',
          title: 'Consistency',
          description: 'Data values don\'t contradict each other within or across systems. Includes referential integrity, cross-field validation, and temporal consistency.',
          examples: [],
        },
        {
          className: 'dimension-3',
          borderColor: '#F59E0B',
          icon: '‚è±Ô∏è',
          title: 'Timeliness',
          description: 'Data is available when needed and represents current state within acceptable latency. Includes data age, refresh frequency, and SLA compliance.',
          examples: [],
        },
      ],
    },
    hasSvgViz: true,
    algorithms: {
      type: 'card-grid',
      title: 'Data Quality Tools Comparison',
      subtitle: 'Evaluating approaches and tools',
      cards: [
        { icon: 'üõ†Ô∏è', title: 'Great Expectations', subtitle: 'Open Source', description: 'Python data pipelines', tags: ['Open Source'] },
        { icon: 'üõ†Ô∏è', title: 'dbt Tests', subtitle: 'Open Source', description: 'SQL transformation testing', tags: ['Open Source'] },
        { icon: 'üõ†Ô∏è', title: 'Monte Carlo', subtitle: 'SaaS', description: 'Data observability', tags: ['SaaS'] },
        { icon: 'üõ†Ô∏è', title: 'Informatica DQ', subtitle: 'Enterprise', description: 'Large enterprise, MDM', tags: ['Enterprise'] },
        { icon: 'üõ†Ô∏è', title: 'Databricks Unity', subtitle: 'Platform', description: 'Lakehouse architecture', tags: ['Platform'] },
        { icon: 'üõ†Ô∏è', title: 'Soda', subtitle: 'Open Core', description: 'Multi-platform quality', tags: ['Open Core'] },
      ],
    },
    tools: {
      title: 'Data Quality Tools Comparison',
      subtitle: 'Essential tools and platforms',
      items: [
        { icon: 'üìä', name: '', vendor: '', description: 'Declarative expectations with docs generation', tags: [] },
        { icon: 'üî∑', name: '', vendor: '', description: 'SQL-based tests in transformation layer', tags: [] },
        { icon: 'üî≠', name: '', vendor: '', description: 'ML-powered anomaly detection', tags: [] },
        { icon: 'üß™', name: '', vendor: '', description: 'SodaCL for declarative quality checks', tags: [] },
      ],
    },
    bestPractices: {
      title: 'Best Practices',
      subtitle: 'Guidelines and recommendations',
      doItems: [
        'Shift Left: Quality at Source ‚Äî Validate data at ingestion point. Catching issues early prevents downstream propagation and reduces remediation cost by 10x compared to fixing in production.',
        'Define Business Context First ‚Äî Work with data stewards to understand what "good" means for each field. Technical checks alone miss semantic quality issues that matter most to users.',
        'Implement Quality Gates ‚Äî Block pipelines when critical thresholds fail. Soft warnings lead to ignored issues. Hard gates force resolution before bad data reaches consumers.',
        'Monitor Trends, Not Just Thresholds ‚Äî Track quality metrics over time. Gradual degradation often signals upstream issues before threshold breaches. Statistical process control catches drift.',
        'Version Your Quality Rules ‚Äî Treat expectations as code‚Äîversion control, test, and deploy through CI/CD. Business changes require synchronized rule updates.',
        'Create Feedback Loops ‚Äî Connect quality alerts to stewardship workflows. Track time-to-resolution, identify recurring issues, and continuously improve source systems.',
      ],
      dontItems: [
      ],
    },
    agent: {
      avatar: 'ü§ñ',
      name: 'DataQualityEngineer',
      role: '',
      description: 'Expert agent for designing quality rules, configuring profiling, implementing validation frameworks, and building monitoring dashboards for enterprise data quality.',
      capabilities: [
        'Great Expectations suite generation',
        'dbt test configuration',
        'Quality scorecard design',
        'Alert threshold tuning',
        'Cleansing rule development',
        'Profiling report analysis',
      ],
      codeFilename: 'great_expectations_suite.py',
      code: ``,
    },
    relatedPages: [
      { number: '26.2', title: 'Metadata Management', description: 'Data catalogs, lineage tracking, and business glossaries', slug: 'metadata' },
      { number: '26.3', title: 'Security & Privacy', description: 'Classification, access controls, and PII protection', slug: 'security-privacy' },
      { number: '26.4', title: 'Data Stewardship', description: 'Ownership, governance councils, and steward programs', slug: 'stewardship' },
    ],
    prevPage: undefined,
    nextPage: { title: '26.2 Metadata Management', slug: 'metadata' },
  },
  {
    slug: 'metadata',
    badge: 'üìö Page 26.2',
    title: 'Metadata Management',
    description: 'Build comprehensive data catalogs, establish business glossaries, and track end-to-end data lineage to enable discovery, understanding, and trust in your enterprise data assets.',
    accentColor: '#10B981',
    accentLight: '#34D399',
    metrics: [
      { value: '3', label: 'Metadata Types' },
      { value: 'E2E', label: 'Lineage Tracking' },
      { value: 'Auto', label: 'Discovery' },
      { value: '100%', label: 'Catalog Coverage' },
    ],
    overview: {
      title: 'Metadata Management',
      subtitle: '',
      subsections: [
        {
          heading: 'Metadata Types',
          paragraphs: [
            'The three categories of metadata that power governance',
            'Effective metadata management addresses three distinct but interconnected categories. Technical metadata describes the structure and physical characteristics of data‚Äîschemas, data types, storage locations, and partitioning. Business metadata provides human context‚Äîdescriptions, ownership, classification, and usage policies. Operational metadata captures runtime behavior‚Äîwhen data was updated, how long jobs ran, access patterns, and query performance. Together, these enable both machine automation and human understanding.',
          ],
        },
        {
          heading: 'Data Lineage',
          paragraphs: [
            'Track data flow from source to consumption',
            'Data lineage visualizes the complete journey of data through your organization‚Äîfrom source systems through transformations to final consumption points. Upstream lineage answers "where did this data come from?" enabling root cause analysis when issues arise. Downstream lineage answers "what depends on this data?" enabling impact analysis before changes. Column-level lineage tracks individual field transformations, essential for regulatory compliance and debugging complex pipelines.',
          ],
        },
        {
          heading: 'Business Glossary',
          paragraphs: [
            'Create shared vocabulary for enterprise data',
            'A business glossary establishes authoritative definitions for key terms used across your organization. Without it, "customer," "revenue," or "active user" can mean different things to different teams, leading to conflicting reports and broken trust. Glossary terms link to catalog assets, showing exactly which tables and columns implement each concept. Hierarchical taxonomies organize terms into domains, while synonyms and related terms capture the full semantic context.',
          ],
        },
      ],
    },
    concepts: {
      title: 'Anti-Patterns to Avoid',
      subtitle: 'Core components and patterns',
      columns: 2,
      cards: [
        {
          className: 'antipattern-0',
          borderColor: '#3B82F6',
          icon: '‚ö†Ô∏è',
          title: 'Catalog as Documentation Project',
          description: 'Treating the catalog as a one-time documentation effort rather than a living system. Initial descriptions become stale within months as schemas evolve.',
          examples: [],
        },
        {
          className: 'antipattern-1',
          borderColor: '#10B981',
          icon: '‚ö†Ô∏è',
          title: 'Orphaned Lineage',
          description: 'Lineage breaks at organizational boundaries‚Äîexternal data sources, manual uploads, and third-party tools create blind spots in the dependency graph.',
          examples: [],
        },
        {
          className: 'antipattern-2',
          borderColor: '#8B5CF6',
          icon: '‚ö†Ô∏è',
          title: 'Glossary by Committee',
          description: 'Endless meetings debating definitions without publishing anything. Perfect becomes the enemy of useful; teams continue using conflicting terms.',
          examples: [],
        },
        {
          className: 'antipattern-3',
          borderColor: '#F59E0B',
          icon: '‚ö†Ô∏è',
          title: 'Build vs. Buy Paralysis',
          description: 'Spending months evaluating catalog tools or attempting to build custom solutions. Meanwhile, teams remain unable to discover or understand data.',
          examples: [],
        },
      ],
    },
    hasSvgViz: true,
    algorithms: {
      type: 'table',
      title: 'Catalog Tools Comparison',
      subtitle: 'Evaluating approaches and tools',
      headers: ['Name', 'Category', 'Best For', 'Complexity', 'Rating'],
      rows: [
        { icon: 'üõ†Ô∏è', name: 'Collibra', tagText: 'Enterprise', tagClass: 'tag-blue', bestFor: 'Large enterprise governance', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'Alation', tagText: 'Enterprise', tagClass: 'tag-green', bestFor: 'Self-service analytics', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'Atlan', tagText: 'SaaS', tagClass: 'tag-purple', bestFor: 'Modern data teams', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'DataHub', tagText: 'Open Source', tagClass: 'tag-orange', bestFor: 'Technical teams, extensibility', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'OpenMetadata', tagText: 'Open Source', tagClass: 'tag-pink', bestFor: 'Open standards, API-first', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'Unity Catalog', tagText: 'Platform', tagClass: 'tag-blue', bestFor: 'Databricks lakehouse', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
      ],
    },
    tools: {
      title: 'Catalog Tools Comparison',
      subtitle: 'Essential tools and platforms',
      items: [
        { icon: 'üìö', name: '', vendor: '', description: 'Full governance platform with policy engine', tags: [] },
        { icon: 'üîç', name: '', vendor: '', description: 'ML-powered discovery and collaboration', tags: [] },
        { icon: 'üåä', name: '', vendor: '', description: 'Modern workspace for data teams', tags: [] },
        { icon: 'üìä', name: '', vendor: '', description: 'LinkedIn\'s extensible metadata platform', tags: [] },
      ],
    },
    bestPractices: {
      title: 'Best Practices',
      subtitle: 'Guidelines and recommendations',
      doItems: [
        'Automate Discovery First ‚Äî Deploy crawlers to populate technical metadata before asking for manual curation. Users won\'t document empty catalogs; they\'ll enhance populated ones.',
        'Start Glossary with High-Value Terms ‚Äî Don\'t boil the ocean. Begin with 20-30 contentious terms that cause actual confusion‚Äîmetrics reported differently, entities defined inconsistently.',
        'Integrate Lineage with Transformation ‚Äî Capture lineage from dbt, Spark, and orchestrators automatically. Manual lineage documentation is never maintained and quickly becomes fiction.',
        'Embed in Developer Workflow ‚Äî Require catalog entries in PR templates. Surface lineage in IDE plugins. Make catalog the default starting point for all data work.',
        'Show Usage Metrics ‚Äî Display query counts, unique users, and last access dates. Popular datasets deserve more curation investment; unused ones may need deprecation.',
        'Connect Quality to Catalog ‚Äî Display data quality scores alongside catalog entries. Users should see freshness, completeness, and accuracy before deciding to use an asset.',
      ],
      dontItems: [
      ],
    },
    agent: {
      avatar: 'ü§ñ',
      name: 'MetadataArchitect',
      role: '',
      description: 'Expert agent for designing catalog schemas, configuring lineage extraction, building glossary taxonomies, and integrating metadata platforms with your data stack.',
      capabilities: [
        'Catalog schema design',
        'Lineage integration setup',
        'Glossary taxonomy building',
        'Crawler configuration',
        'Tag and classification design',
        'Usage analytics setup',
      ],
      codeFilename: 'datahub_ingestion.yaml',
      code: ``,
    },
    relatedPages: [
      { number: '26.1', title: 'Data Quality', description: 'Profiling, validation rules, and quality monitoring', slug: 'data-quality' },
      { number: '26.3', title: 'Security & Privacy', description: 'Classification, access controls, and PII protection', slug: 'security-privacy' },
      { number: '26.4', title: 'Data Stewardship', description: 'Ownership, governance councils, and steward programs', slug: 'stewardship' },
    ],
    prevPage: { title: '26.1 Data Quality Management', slug: 'data-quality' },
    nextPage: { title: '26.3 Security & Privacy', slug: 'security-privacy' },
  },
  {
    slug: 'security-privacy',
    badge: 'üîí Page 26.3',
    title: 'Security & Privacy',
    description: 'Implement comprehensive data protection with classification frameworks, role-based access controls, encryption strategies, and PII handling to meet regulatory requirements and protect sensitive assets.',
    accentColor: '#8B5CF6',
    accentLight: '#A78BFA',
    metrics: [
      { value: '4', label: 'Classification Levels' },
      { value: 'RBAC', label: 'Access Model' },
      { value: 'AES-256', label: 'Encryption Standard' },
      { value: 'GDPR', label: 'Privacy Compliant' },
    ],
    overview: {
      title: 'Security & Privacy',
      subtitle: '',
      subsections: [
        {
          heading: 'Data Classification',
          paragraphs: [
            'Categorize data by sensitivity for appropriate protection',
            'Data classification is the foundation of security governance‚Äîyou can\'t protect what you haven\'t identified. A consistent classification scheme enables automated policy enforcement, appropriate access provisioning, and proportional security investment. Most organizations use four levels: Public data that can be freely shared, Internal data for employees only, Confidential data with restricted business access, and Restricted data requiring the strictest controls. Classification should flow from data catalogs through to access management and encryption decisions.',
          ],
        },
        {
          heading: 'Access Control Models',
          paragraphs: [
            'Implement appropriate authorization frameworks',
            'Access control determines who can access what data under which conditions. Role-Based Access Control (RBAC) assigns permissions to roles, which are then assigned to users‚Äîsimple and auditable but can lead to role explosion. Attribute-Based Access Control (ABAC) makes decisions based on user attributes, resource attributes, and environmental conditions‚Äîmore flexible but harder to understand and audit. Most organizations use RBAC as a foundation with ABAC for fine-grained exceptions.',
          ],
        },
        {
          heading: 'PII Protection',
          paragraphs: [
            'Identify and protect personally identifiable information',
            'Personally Identifiable Information requires special handling under GDPR, CCPA, and other privacy regulations. Direct identifiers like names and SSNs clearly identify individuals. Quasi-identifiers like ZIP codes and birth dates can identify when combined. Protected categories include health information (PHI under HIPAA), financial data (PCI-DSS), and children\'s data (COPPA). Protection techniques range from encryption at rest and in transit to masking, tokenization, and differential privacy for analytics.',
          ],
        },
      ],
    },
    concepts: {
      title: 'Anti-Patterns to Avoid',
      subtitle: 'Core components and patterns',
      columns: 2,
      cards: [
        {
          className: 'antipattern-0',
          borderColor: '#3B82F6',
          icon: '‚ö†Ô∏è',
          title: 'Security by Obscurity',
          description: 'Assuming data is safe because it\'s in an "internal" database or has a non-obvious table name. Determined attackers will find it.',
          examples: [],
        },
        {
          className: 'antipattern-1',
          borderColor: '#10B981',
          icon: '‚ö†Ô∏è',
          title: 'Over-Permissive Roles',
          description: 'Granting broad "admin" or "analyst" roles because fine-grained permissions are tedious. Creates massive blast radius when compromised.',
          examples: [],
        },
        {
          className: 'antipattern-2',
          borderColor: '#8B5CF6',
          icon: '‚ö†Ô∏è',
          title: 'Incomplete PII Inventory',
          description: 'Assuming you know where all PII lives based on system documentation. Data spreads to exports, emails, and shadow IT systems.',
          examples: [],
        },
        {
          className: 'antipattern-3',
          borderColor: '#F59E0B',
          icon: '‚ö†Ô∏è',
          title: 'Encryption Key Sprawl',
          description: 'Different encryption keys for every system without centralized management. Keys get lost, access becomes impossible, rotation is inconsistent.',
          examples: [],
        },
      ],
    },
    hasSvgViz: true,
    algorithms: {
      type: 'card-grid',
      title: 'PII Protection',
      subtitle: 'Evaluating approaches and tools',
      cards: [
        { icon: 'üõ†Ô∏è', title: 'Encryption', subtitle: 'Transform data using cryptographic keys', description: 'Data at rest, in transit', tags: ['Transform data using cryptographic keys'] },
        { icon: 'üõ†Ô∏è', title: 'Tokenization', subtitle: 'Replace sensitive data with non-sensitive tokens', description: 'Payment data, cross-system', tags: ['Replace sensitive data with non-sensitive tokens'] },
        { icon: 'üõ†Ô∏è', title: 'Masking', subtitle: 'Hide portions of data (e.g., XXX-XX-1234)', description: 'Display, non-prod environments', tags: ['Hide portions of data (e.g., XXX-XX-1234)'] },
        { icon: 'üõ†Ô∏è', title: 'Anonymization', subtitle: 'Remove all identifying information permanently', description: 'Research, public datasets', tags: ['Remove all identifying information permanently'] },
        { icon: 'üõ†Ô∏è', title: 'Differential Privacy', subtitle: 'Add mathematical noise to protect individuals', description: 'Aggregate analytics, ML', tags: ['Add mathematical noise to protect individuals'] },
        { icon: 'üõ†Ô∏è', title: 'GDPR', subtitle: 'European Union', description: 'Yes', tags: ['European Union'] },
        { icon: 'üõ†Ô∏è', title: 'CCPA/CPRA', subtitle: 'California, USA', description: 'Yes', tags: ['California, USA'] },
        { icon: 'üõ†Ô∏è', title: 'LGPD', subtitle: 'Brazil', description: 'Yes', tags: ['Brazil'] },
      ],
    },
    tools: {
      title: 'Security Tools Comparison',
      subtitle: 'Essential tools and platforms',
      items: [
        { icon: 'üîê', name: '', vendor: '', description: 'Apache Ranger-based cross-platform access', tags: [] },
        { icon: 'üé≠', name: '', vendor: '', description: 'Policy-based data masking and access', tags: [] },
        { icon: 'üîç', name: '', vendor: '', description: 'ML-powered PII discovery and classification', tags: [] },
        { icon: 'üîë', name: '', vendor: '', description: 'Encryption keys and secrets lifecycle', tags: [] },
      ],
    },
    bestPractices: {
      title: 'Best Practices',
      subtitle: 'Guidelines and recommendations',
      doItems: [
        'Classify Before You Control ‚Äî Deploy automated classification discovery before building access policies. You can\'t protect sensitive data you haven\'t identified and labeled.',
        'Implement Least Privilege ‚Äî Grant minimum necessary access by default. Users should request elevated access with justification and time limits for sensitive data.',
        'Encrypt at Rest and In Transit ‚Äî Use AES-256 for storage, TLS 1.3 for transmission. Manage keys separately from data‚Äîconsider dedicated key management services.',
        'Mask for Non-Production ‚Äî Never use real PII in development, testing, or training environments. Synthetic data or masked copies eliminate unnecessary exposure.',
        'Audit Access Continuously ‚Äî Log all access to sensitive data. Review logs for anomalies‚Äîunusual access patterns often indicate compromise or policy violations.',
        'Plan for Data Subject Requests ‚Äî Build processes for GDPR/CCPA requests before they arrive. Know where PII lives, how to export it, and how to delete it completely.',
      ],
      dontItems: [
      ],
    },
    agent: {
      avatar: 'ü§ñ',
      name: 'SecurityArchitect',
      role: '',
      description: 'Expert agent for designing classification schemes, implementing access controls, configuring encryption, and ensuring privacy compliance across your data platforms.',
      capabilities: [
        'Classification scheme design',
        'RBAC/ABAC policy configuration',
        'Encryption architecture',
        'PII detection rules',
        'Compliance mapping',
        'Access audit setup',
      ],
      codeFilename: 'unity_catalog_grants.sql',
      code: ``,
    },
    relatedPages: [
      { number: '26.2', title: 'Metadata Management', description: 'Data catalogs, lineage tracking, and business glossaries', slug: 'metadata' },
      { number: '26.4', title: 'Data Stewardship', description: 'Ownership, governance councils, and steward programs', slug: 'stewardship' },
      { number: '26.5', title: 'Compliance & Audit', description: 'Regulatory frameworks, audit trails, and certifications', slug: 'compliance' },
    ],
    prevPage: { title: '26.2 Metadata Management', slug: 'metadata' },
    nextPage: { title: '26.4 Data Stewardship', slug: 'stewardship' },
  },
  {
    slug: 'stewardship',
    badge: 'üë• Page 26.4',
    title: 'Data Stewardship',
    description: 'Establish clear data ownership, build effective governance councils, and implement stewardship programs that scale across your organization to ensure accountability and continuous improvement.',
    accentColor: '#F59E0B',
    accentLight: '#FBBF24',
    metrics: [
      { value: '3', label: 'Steward Levels' },
      { value: 'RACI', label: 'Accountability Model' },
      { value: 'Council', label: 'Decision Body' },
      { value: 'Federated', label: 'Operating Model' },
    ],
    overview: {
      title: 'Data Stewardship',
      subtitle: '',
      subsections: [
        {
          heading: 'Stewardship Roles',
          paragraphs: [
            'Define clear responsibilities at each level',
            'Effective stewardship programs define distinct roles with clear responsibilities and escalation paths. Data Owners are senior business leaders accountable for data assets in their domain‚Äîthey make policy decisions and resolve cross-functional disputes. Data Stewards are subject matter experts who maintain day-to-day data quality, documentation, and access requests. Technical Stewards handle the physical implementation‚Äîschema changes, ETL modifications, and system configurations. This separation ensures business accountability while leveraging appropriate expertise.',
          ],
        },
        {
          heading: 'Organizational Structure',
          paragraphs: [
            'Operating models for data governance',
            'Data governance operating models range from centralized to federated, with most organizations adopting a hybrid approach. Centralized models provide consistency but create bottlenecks and lack domain expertise. Fully decentralized models are fast but inconsistent. The federated model balances local autonomy with enterprise standards‚Äîa central governance team sets policies and provides tools, while domain stewards execute within their areas. This "hub and spoke" structure scales effectively across large organizations.',
          ],
        },
        {
          heading: 'Governance Council',
          paragraphs: [
            'Establish decision-making bodies',
            'A Data Governance Council provides cross-functional leadership for data initiatives. It typically includes data owners from major domains, IT leadership, legal/compliance, and a CDO or governance lead as chair. The council sets enterprise data strategy, resolves cross-domain disputes, approves policies, and prioritizes governance investments. Effective councils meet monthly with clear agendas, decision rights, and escalation procedures for issues requiring executive attention.',
          ],
        },
      ],
    },
    concepts: {
      title: 'Stewardship Roles',
      subtitle: 'Core components and patterns',
      columns: 2,
      cards: [
        {
          className: 'role-0',
          borderColor: '#3B82F6',
          icon: 'üëî',
          title: 'Data Owner',
          description: 'Senior business leader accountable for data assets in their domain. Makes policy decisions and allocates resources for data initiatives.',
          examples: ['Approve access policies and exceptions', 'Resolve cross-domain data disputes', 'Allocate budget for data quality initiatives', 'Champion governance in leadership forums', 'Sign off on data sharing agreements'],
        },
        {
          className: 'role-1',
          borderColor: '#10B981',
          icon: 'üë•',
          title: 'Data Steward',
          description: 'Subject matter expert responsible for day-to-day data quality, documentation, and access management within their domain.',
          examples: ['Define and document business rules', 'Review and approve access requests', 'Monitor data quality dashboards', 'Maintain catalog descriptions', 'Investigate and remediate issues'],
        },
        {
          className: 'role-2',
          borderColor: '#8B5CF6',
          icon: '‚öôÔ∏è',
          title: 'Technical Steward',
          description: 'Technical expert responsible for physical implementation of data standards, schema management, and system configurations.',
          examples: ['Implement schema changes', 'Configure access controls in systems', 'Build data quality checks', 'Maintain ETL/ELT pipelines', 'Support technical troubleshooting'],
        },
        {
          className: 'concept-3',
          borderColor: '#F59E0B',
          icon: 'üí°',
          title: 'Data Stewardship',
          description: 'Establish clear data ownership, build effective governance councils, and implement stewardship programs that scale across your organization to ensure accountability and continuous improvement.',
          examples: [],
        },
      ],
    },
    hasSvgViz: true,
    algorithms: {
      type: 'table',
      title: 'Stewardship Roles',
      subtitle: 'Evaluating approaches and tools',
      headers: ['Name', 'Category', 'Best For', 'Complexity', 'Rating'],
      rows: [
        { icon: 'üõ†Ô∏è', name: 'Define data policies', tagText: 'A', tagClass: 'tag-blue', bestFor: 'R', complexity: 'medium', rating: 'R' },
        { icon: 'üõ†Ô∏è', name: 'Approve access requests', tagText: 'C', tagClass: 'tag-green', bestFor: 'I', complexity: 'medium', rating: 'A' },
        { icon: 'üõ†Ô∏è', name: 'Monitor data quality', tagText: 'I', tagClass: 'tag-purple', bestFor: 'C', complexity: 'medium', rating: 'A' },
        { icon: 'üõ†Ô∏è', name: 'Resolve data issues', tagText: 'C', tagClass: 'tag-orange', bestFor: 'A', complexity: 'medium', rating: 'R' },
        { icon: 'üõ†Ô∏è', name: 'Maintain documentation', tagText: 'I', tagClass: 'tag-pink', bestFor: 'R', complexity: 'medium', rating: 'A' },
        { icon: 'üõ†Ô∏è', name: 'Schema changes', tagText: 'A', tagClass: 'tag-blue', bestFor: 'I', complexity: 'medium', rating: 'C' },
        { icon: 'üõ†Ô∏è', name: 'Strategic Review', tagText: 'Quarterly', tagClass: 'tag-green', bestFor: 'Roadmap, budget, metrics', complexity: 'medium', rating: '2 hours' },
        { icon: 'üõ†Ô∏è', name: 'Council Meeting', tagText: 'Monthly', tagClass: 'tag-purple', bestFor: 'Policy decisions, escalations', complexity: 'medium', rating: '1 hour' },
        { icon: 'üõ†Ô∏è', name: 'Working Group', tagText: 'Bi-weekly', tagClass: 'tag-orange', bestFor: 'Operational issues, standards', complexity: 'medium', rating: '1 hour' },
        { icon: 'üõ†Ô∏è', name: 'Steward Sync', tagText: 'Weekly', tagClass: 'tag-pink', bestFor: 'Issue triage, coordination', complexity: 'medium', rating: '30 min' },
        { icon: 'üõ†Ô∏è', name: 'Collibra', tagText: 'Enterprise', tagClass: 'tag-blue', bestFor: 'Large enterprise governance', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'Alation', tagText: 'Enterprise', tagClass: 'tag-green', bestFor: 'Self-service, collaboration', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'Atlan', tagText: 'SaaS', tagClass: 'tag-purple', bestFor: 'Modern data teams', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'DataHub', tagText: 'Open Source', tagClass: 'tag-orange', bestFor: 'Technical teams, flexibility', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'OpenMetadata', tagText: 'Open Source', tagClass: 'tag-pink', bestFor: 'API-first, extensibility', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
      ],
    },
    tools: {
      title: 'Steward Program Lifecycle',
      subtitle: 'Essential tools and platforms',
      items: [
        { icon: 'üìä', name: '', vendor: '', description: 'Workflow automation for steward tasks', tags: [] },
        { icon: 'üîç', name: '', vendor: '', description: 'Collaborative data curation and Q&A', tags: [] },
        { icon: 'üìã', name: '', vendor: '', description: 'Slack-like collaboration for data teams', tags: [] },
        { icon: 'üìà', name: '', vendor: '', description: 'Ownership tracking and documentation', tags: [] },
      ],
    },
    bestPractices: {
      title: 'Best Practices',
      subtitle: 'Guidelines and recommendations',
      doItems: [
        'Start with High-Value Domains ‚Äî Pilot stewardship in domains with clear pain points‚Äîcustomer data, financial reporting, or regulatory data. Quick wins build momentum.',
        'Make Stewardship Part of the Job ‚Äî Include stewardship responsibilities in job descriptions and performance reviews. Unfunded mandates create resentment and abandonment.',
        'Provide Tools, Not Just Responsibility ‚Äî Equip stewards with dashboards, workflows, and automation. Manual spreadsheet-based governance doesn\'t scale and burns out stewards.',
        'Create Community of Practice ‚Äî Connect stewards across domains for knowledge sharing. Regular forums, Slack channels, and shared documentation build collective capability.',
        'Establish Clear Escalation Paths ‚Äî Define when stewards should escalate to owners or council. Unclear boundaries lead to either bottlenecks or inappropriate decisions.',
        'Measure and Report Progress ‚Äî Track stewardship metrics‚Äîdocumentation coverage, issue resolution time, quality scores. Visibility drives accountability and improvement.',
      ],
      dontItems: [
      ],
    },
    agent: {
      avatar: 'ü§ñ',
      name: 'StewardshipAdvisor',
      role: '',
      description: 'Expert agent for designing stewardship programs, defining roles and responsibilities, building governance councils, and creating sustainable data accountability structures.',
      capabilities: [
        'Role definition and RACI',
        'Operating model design',
        'Council charter development',
        'Steward program planning',
        'Governance metrics design',
        'Domain mapping',
      ],
      codeFilename: 'stewardship_config.yaml',
      code: ``,
    },
    relatedPages: [
      { number: '26.3', title: 'Security & Privacy', description: 'Classification, access controls, and PII protection', slug: 'security-privacy' },
      { number: '26.5', title: 'Compliance & Audit', description: 'Regulatory frameworks, audit trails, and certifications', slug: 'compliance' },
      { number: '26.6', title: 'Data Architecture', description: 'MDM, reference data, and architectural patterns', slug: 'architecture' },
    ],
    prevPage: { title: '26.3 Security & Privacy', slug: 'security-privacy' },
    nextPage: { title: '26.5 Compliance & Audit', slug: 'compliance' },
  },
  {
    slug: 'compliance',
    badge: '‚öñÔ∏è Page 26.5',
    title: 'Compliance & Audit',
    description: 'Build comprehensive audit trails, implement control frameworks, achieve certifications, and maintain continuous compliance with regulatory requirements across your data ecosystem.',
    accentColor: '#EC4899',
    accentLight: '#F472B6',
    metrics: [
      { value: 'SOC 2', label: 'Type II Certified' },
      { value: '7 Years', label: 'Retention Period' },
      { value: 'Real-time', label: 'Audit Logging' },
      { value: 'ISO 27001', label: 'Security Standard' },
    ],
    overview: {
      title: 'Compliance & Audit',
      subtitle: '',
      subsections: [
        {
          heading: 'Compliance Frameworks',
          paragraphs: [
            'Standards and regulations governing data management',
            'Compliance frameworks provide structured approaches to demonstrating security and data protection capabilities. SOC 2 is the de facto standard for SaaS companies, focusing on security, availability, and confidentiality. ISO 27001 provides a comprehensive information security management system recognized globally. Industry-specific frameworks like HIPAA, PCI-DSS, and FedRAMP address sector requirements with prescriptive controls.',
          ],
        },
        {
          heading: 'Audit Trail Architecture',
          paragraphs: [
            'Comprehensive logging for compliance and investigation',
            'Audit trails capture who accessed what data, when, and what they did with it. Effective audit logging requires capturing events at multiple layers‚Äîapplication, database, and infrastructure. Logs must be tamper-evident, retained for required periods (often 7 years for financial data), and searchable for investigations. Centralized log management with SIEM integration enables real-time alerting on suspicious patterns.',
          ],
        },
        {
          heading: 'Certifications & Attestations',
          paragraphs: [
            'Third-party validation of security controls',
            'Certifications provide independent verification that your organization meets established security standards. The certification process typically involves gap assessment, remediation, evidence collection, and formal audit by accredited assessors. Maintaining certification requires continuous compliance monitoring and periodic reassessment‚Äîmost certifications have annual audit requirements.',
          ],
        },
      ],
    },
    concepts: {
      title: 'Compliance Frameworks',
      subtitle: 'Core components and patterns',
      columns: 2,
      cards: [
        {
          className: 'framework-0',
          borderColor: '#3B82F6',
          icon: 'üîê',
          title: 'SOC 2',
          description: 'AICPA standard for service providers. Type I assesses control design; Type II tests operating effectiveness over time.',
          examples: ['Security (required)', 'Availability', 'Processing Integrity', 'Confidentiality', 'Privacy'],
        },
        {
          className: 'framework-1',
          borderColor: '#10B981',
          icon: 'üåê',
          title: 'ISO 27001',
          description: 'International standard for establishing, implementing, and maintaining an information security management system (ISMS).',
          examples: ['Risk assessment', 'Security policies', 'Asset management', 'Access control', 'Incident management'],
        },
        {
          className: 'framework-2',
          borderColor: '#8B5CF6',
          icon: 'üèõÔ∏è',
          title: 'NIST CSF',
          description: 'Voluntary framework providing a common language for managing cybersecurity risk. Widely adopted as a baseline.',
          examples: ['Identify', 'Protect', 'Detect', 'Respond', 'Recover'],
        },
        {
          className: 'concept-3',
          borderColor: '#F59E0B',
          icon: 'üí°',
          title: 'Compliance & Audit',
          description: 'Build comprehensive audit trails, implement control frameworks, achieve certifications, and maintain continuous compliance with regulatory requirements across your data ecosystem.',
          examples: [],
        },
      ],
    },
    hasSvgViz: true,
    algorithms: {
      type: 'card-grid',
      title: 'Compliance Frameworks',
      subtitle: 'Evaluating approaches and tools',
      cards: [
        { icon: 'üõ†Ô∏è', title: 'SOC 2 Type II', subtitle: 'Service providers', description: 'SaaS companies, B2B', tags: ['Service providers'] },
        { icon: 'üõ†Ô∏è', title: 'ISO 27001', subtitle: 'Any organization', description: 'Global enterprises', tags: ['Any organization'] },
        { icon: 'üõ†Ô∏è', title: 'NIST CSF', subtitle: 'Any organization', description: 'Baseline framework', tags: ['Any organization'] },
        { icon: 'üõ†Ô∏è', title: 'HIPAA', subtitle: 'Healthcare data', description: 'Healthcare, health tech', tags: ['Healthcare data'] },
        { icon: 'üõ†Ô∏è', title: 'PCI-DSS', subtitle: 'Payment card data', description: 'Payment processing', tags: ['Payment card data'] },
        { icon: 'üõ†Ô∏è', title: 'FedRAMP', subtitle: 'US federal cloud', description: 'Government contractors', tags: ['US federal cloud'] },
        { icon: 'üõ†Ô∏è', title: 'Authentication', subtitle: 'Login success/failure, MFA events, session management', description: 'High', tags: ['Login success/failure, MFA events, session management'] },
        { icon: 'üõ†Ô∏è', title: 'Authorization', subtitle: 'Permission changes, role assignments, access denials', description: 'High', tags: ['Permission changes, role assignments, access denials'] },
      ],
    },
    tools: {
      title: 'Compliance Tools Comparison',
      subtitle: 'Essential tools and platforms',
      items: [
        { icon: '‚úÖ', name: '', vendor: '', description: 'Automated evidence collection and monitoring', tags: [] },
        { icon: 'üõ°Ô∏è', name: '', vendor: '', description: 'Real-time control monitoring dashboard', tags: [] },
        { icon: 'üìä', name: '', vendor: '', description: 'Log management and security analytics', tags: [] },
        { icon: 'üîç', name: '', vendor: '', description: 'Cloud security posture management', tags: [] },
      ],
    },
    bestPractices: {
      title: 'Best Practices',
      subtitle: 'Guidelines and recommendations',
      doItems: [
        'Automate Evidence Collection ‚Äî Integrate GRC tools with your tech stack to pull evidence automatically. Manual evidence gathering doesn\'t scale and creates last-minute scrambles.',
        'Map Controls Once, Use Many Times ‚Äî Create a unified control framework that maps to multiple certifications. One well-designed control can satisfy SOC 2, ISO, and HIPAA requirements.',
        'Maintain Continuous Compliance ‚Äî Monitor control effectiveness in real-time rather than point-in-time. Drift detection catches issues months before auditors would find them.',
        'Embed Security in Development ‚Äî Shift compliance left into CI/CD pipelines. Automated security scanning and policy-as-code prevent non-compliant deployments.',
        'Document Exception Processes ‚Äî Define how to request, approve, and track exceptions to policies. Auditors accept well-documented exceptions; they don\'t accept undocumented violations.',
        'Train and Test Regularly ‚Äî Annual security training and tabletop exercises demonstrate operational effectiveness. Evidence of training is required by virtually every framework.',
      ],
      dontItems: [
      ],
    },
    agent: {
      avatar: 'ü§ñ',
      name: 'ComplianceAdvisor',
      role: '',
      description: 'Expert agent for navigating compliance frameworks, preparing for audits, mapping controls across standards, and implementing continuous compliance monitoring.',
      capabilities: [
        'Framework mapping',
        'Gap assessment',
        'Audit preparation',
        'Evidence collection',
        'Control monitoring',
        'Policy generation',
      ],
      codeFilename: 'compliance_config.yaml',
      code: ``,
    },
    relatedPages: [
      { number: '26.3', title: 'Security & Privacy', description: 'Classification, access controls, and PII protection', slug: 'security-privacy' },
      { number: '26.4', title: 'Data Stewardship', description: 'Ownership, governance councils, and steward programs', slug: 'stewardship' },
      { number: '26.6', title: 'Data Architecture', description: 'MDM, reference data, and architectural patterns', slug: 'architecture' },
    ],
    prevPage: { title: '26.4 Data Stewardship', slug: 'stewardship' },
    nextPage: { title: '26.6 Data Architecture & MDM', slug: 'architecture' },
  },
  {
    slug: 'architecture',
    badge: 'üèõÔ∏è Page 26.6',
    title: 'Data Architecture & MDM',
    description: 'Design scalable data architectures, implement master data management for critical domains, manage reference data, and choose the right patterns for your organization\'s data landscape.',
    accentColor: '#06B6D4',
    accentLight: '#22D3EE',
    metrics: [
      { value: 'MDM', label: 'Golden Records' },
      { value: '4', label: 'Master Domains' },
      { value: 'Mesh', label: 'Architecture Pattern' },
      { value: 'Hub', label: 'Integration Style' },
    ],
    overview: {
      title: 'Data Architecture & MDM',
      subtitle: '',
      subsections: [
        {
          heading: 'Master Data Management',
          paragraphs: [
            'Create authoritative golden records for critical domains',
            'Master Data Management (MDM) creates and maintains authoritative "golden records" for core business entities that are shared across systems. Unlike transactional data that describes events, master data describes the nouns of your business‚Äîcustomers, products, locations, employees, and suppliers. MDM platforms collect data from multiple sources, apply match/merge logic to identify duplicates, and publish consolidated records back to consuming systems.',
          ],
        },
        {
          heading: 'Architecture Patterns',
          paragraphs: [
            'Choose the right approach for your organization',
            'Modern data architecture has evolved beyond traditional centralized approaches. Data Mesh treats data as a product owned by domain teams, while Data Fabric provides a unified virtualization layer across distributed sources. The choice depends on organizational structure, team maturity, and specific use cases. Most enterprises adopt hybrid approaches that combine elements of multiple patterns.',
          ],
        },
        {
          heading: 'Reference Data Management',
          paragraphs: [
            'Standardize codes, classifications, and hierarchies',
            'Reference data consists of the codes, classifications, and hierarchies that provide context for transactional and master data. While master data describes business entities, reference data describes the valid values used to classify those entities. Effective reference data management ensures consistency across systems‚Äîeveryone uses the same country codes, currency codes, and product categories.',
          ],
        },
      ],
    },
    concepts: {
      title: 'Key Concepts',
      subtitle: 'Core components and patterns',
      columns: 2,
      cards: [
        {
          className: 'concept-0',
          borderColor: '#3B82F6',
          icon: 'üè¢',
          title: 'Centralized Data Warehouse',
          description: 'All data consolidated into a single repository owned by a central team. Best for organizations with strong BI needs, limited data engineering resources, and well-defined reporting requirements.',
          examples: [],
        },
        {
          className: 'concept-1',
          borderColor: '#10B981',
          icon: 'üåä',
          title: 'Data Lake / Lakehouse',
          description: 'Raw data stored in native formats with schema applied at read time. Lakehouse adds ACID transactions and performance optimizations. Ideal for diverse data types and exploratory analytics.',
          examples: [],
        },
        {
          className: 'concept-2',
          borderColor: '#8B5CF6',
          icon: 'üï∏Ô∏è',
          title: 'Data Mesh',
          description: 'Domain teams own their data as products with federated governance. Requires mature engineering practices and self-service infrastructure. Scales with organizational complexity.',
          examples: [],
        },
        {
          className: 'concept-3',
          borderColor: '#F59E0B',
          icon: 'üîó',
          title: 'Data Fabric',
          description: 'Virtualization layer providing unified access to data wherever it lives. Uses AI/ML for automated integration and governance. Reduces data movement while enabling consistent access.',
          examples: [],
        },
      ],
    },
    hasSvgViz: true,
    algorithms: {
      type: 'table',
      title: 'Architecture Patterns',
      subtitle: 'Evaluating approaches and tools',
      headers: ['Name', 'Category', 'Best For', 'Complexity', 'Rating'],
      rows: [
        { icon: 'üõ†Ô∏è', name: 'Data Warehouse', tagText: 'BI reporting, regulated industries', tagClass: 'tag-blue', bestFor: 'Low', complexity: 'medium', rating: 'Centralized' },
        { icon: 'üõ†Ô∏è', name: 'Data Lakehouse', tagText: 'ML/AI, diverse data types', tagClass: 'tag-green', bestFor: 'Medium', complexity: 'medium', rating: 'Centralized' },
        { icon: 'üõ†Ô∏è', name: 'Data Mesh', tagText: 'Large orgs, domain autonomy', tagClass: 'tag-purple', bestFor: 'High', complexity: 'medium', rating: 'Federated' },
        { icon: 'üõ†Ô∏è', name: 'Data Fabric', tagText: 'Hybrid environments, real-time', tagClass: 'tag-orange', bestFor: 'Medium', complexity: 'medium', rating: 'Hybrid' },
        { icon: 'üõ†Ô∏è', name: 'Country Codes', tagText: 'ISO 3166 Standard', tagClass: 'tag-pink', bestFor: 'All systems', complexity: 'medium', rating: 'Rare (political changes)' },
        { icon: 'üõ†Ô∏è', name: 'Product Categories', tagText: 'Merchandising Team', tagClass: 'tag-blue', bestFor: 'Sales, Marketing, Finance', complexity: 'medium', rating: 'Quarterly' },
        { icon: 'üõ†Ô∏è', name: 'Cost Centers', tagText: 'Finance', tagClass: 'tag-green', bestFor: 'ERP, HR, Procurement', complexity: 'medium', rating: 'Annual (budget cycle)' },
        { icon: 'üõ†Ô∏è', name: 'Sales Territories', tagText: 'Sales Operations', tagClass: 'tag-purple', bestFor: 'CRM, BI, Compensation', complexity: 'medium', rating: 'Semi-annual' },
        { icon: 'üõ†Ô∏è', name: 'Informatica MDM', tagText: 'Enterprise', tagClass: 'tag-orange', bestFor: 'Large enterprise, complex', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'SAP Master Data', tagText: 'Enterprise', tagClass: 'tag-pink', bestFor: 'SAP-centric orgs', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'Reltio', tagText: 'Cloud SaaS', tagClass: 'tag-blue', bestFor: 'Cloud-first, modern stack', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'Tamr', tagText: 'Cloud SaaS', tagClass: 'tag-green', bestFor: 'ML-driven matching', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
        { icon: 'üõ†Ô∏è', name: 'Databricks Unity Catalog', tagText: 'Platform', tagClass: 'tag-purple', bestFor: 'Lakehouse governance', complexity: 'medium', rating: '‚≠ê‚≠ê‚≠ê‚≠ê' },
      ],
    },
    tools: {
      title: 'MDM & Architecture Tools',
      subtitle: 'Essential tools and platforms',
      items: [
        { icon: 'üè¢', name: '', vendor: '', description: 'Industry leader for complex multi-domain MDM', tags: [] },
        { icon: '‚òÅÔ∏è', name: '', vendor: '', description: 'Cloud-native with real-time graph capabilities', tags: [] },
        { icon: 'ü§ñ', name: '', vendor: '', description: 'Machine learning for entity resolution', tags: [] },
        { icon: '‚ö°', name: '', vendor: '', description: 'Unified analytics with governance built-in', tags: [] },
      ],
    },
    bestPractices: {
      title: 'Best Practices',
      subtitle: 'Guidelines and recommendations',
      doItems: [
        'Start with Customer MDM ‚Äî Customer master typically offers highest ROI‚Äîduplicate elimination, 360¬∞ views, and improved marketing. Prove value before expanding to other domains.',
        'Define Survivorship Rules Early ‚Äî Document which source system wins for each attribute when records merge. Unclear survivorship creates downstream confusion and rework.',
        'Invest in Match Quality ‚Äî Spend time tuning match rules to minimize false positives (wrong merges) and false negatives (missed duplicates). Both erode trust in golden records.',
        'Establish Data Contracts ‚Äî Define explicit contracts between producers and consumers‚Äîschema, SLAs, quality expectations. Contracts prevent breaking changes and clarify responsibilities.',
        'Build Self-Service Capabilities ‚Äî Enable domain teams to discover, access, and use data without central team bottlenecks. Investment in platform capabilities multiplies productivity.',
        'Plan for Historical Changes ‚Äî Implement slowly changing dimensions (SCD) from the start. Retrofitting historical tracking is painful‚Äîdesign for it upfront.',
      ],
      dontItems: [
      ],
    },
    agent: {
      avatar: 'ü§ñ',
      name: 'DataArchitect',
      role: '',
      description: 'Expert agent for designing data architectures, implementing MDM programs, defining data models, and selecting appropriate patterns for your organization\'s needs.',
      capabilities: [
        'MDM program design',
        'Architecture pattern selection',
        'Data modeling',
        'Match/merge configuration',
        'Reference data design',
        'Integration patterns',
      ],
      codeFilename: 'mdm_customer_model.yaml',
      code: ``,
    },
    relatedPages: [
      { number: '26.2', title: 'Metadata Management', description: 'Data catalogs, lineage tracking, and business glossaries', slug: 'metadata' },
      { number: '26.4', title: 'Data Stewardship', description: 'Ownership, governance councils, and steward programs', slug: 'stewardship' },
    ],
    prevPage: { title: '26.5 Compliance & Audit', slug: 'compliance' },
    nextPage: undefined,
  },
]

registerPages('governance', pages)
export default pages
